game_play_loop:
  start_tick: 0
  max_ticks: 300000
  rng_seed: 42
  game_runners:
    - play_every: 1
      pinned_player: dqn
      opponent_pool: ["negamax"]
      log_every: 100
      dump_games_every: null
      dump_games_location: null
      writer_prefix: games/dqn
      export_episodes: true
    - play_every: 10
      pinned_player: dqn_greedy
      opponent_pool: ["negamax"]
      log_every: 10
      dump_games_every: 1000
      dump_games_location: games/${now:%Y-%m-%d_%H-%M-%S}
      writer_prefix: games/dqn_greedy
      export_episodes: false
  players:
    random:
      type: RandomAgent
      rng_seed: 42
    always0:
      type: AlwaysPlayFixedColumnAgent
      column: 0
    always1:
      type: AlwaysPlayFixedColumnAgent
      column: 1
    always2:
      type: AlwaysPlayFixedColumnAgent
      column: 2
    always3:
      type: AlwaysPlayFixedColumnAgent
      column: 3
    always4:
      type: AlwaysPlayFixedColumnAgent
      column: 4
    always5:
      type: AlwaysPlayFixedColumnAgent
      column: 5
    always6:
      type: AlwaysPlayFixedColumnAgent
      column: 6
    negamax:
      type: NegamaxAgent
      h: 6
      w: 7
      search_depth: 2
    dqn:
      type: QAgent
      update_from_queue: true
      html_log_file: null
      html_log_max_games: null
      html_log_game_write_interval: null
      qfunction:
        type: ConvNetQFunction
        input_shape: [2,6,7]
        num_actions: 7
        load_from: null
        device: cpu
      action_picker: 
        type: EpsilonGreedyPicker
        epsilon: 
          type: linear_schedule
          start: 1.0
          end: 0.1
          steps: 150000
        rng_seed: 42
        writer_prefix: "agents/dqn/epsilon"
    dqn_greedy:
      type: QAgent
      update_from_queue: true
      html_log_file: html_game_log.greedy.html
      html_log_max_games: 1000
      html_log_game_write_interval: 10
      qfunction:
        type: ConvNetQFunction
        input_shape: [2,6,7]
        num_actions: 7
        load_from: null
        device: cpu
      action_picker: 
        type: EpsilonGreedyPicker
        epsilon: 
          type: fixed
          value: 0.0
        rng_seed: 42
        writer_prefix: agents/dqn/epsilon
learner:
  start_tick: 0
  max_ticks: 500000
  qfunction:
    type: ConvNetQFunction
    input_shape: [2,6,7]
    num_actions: 7
    load_from: null
    device: cuda
  step_lengths:
    1: 1.0
  replay_buffer_size: 10000
  replay_buffer_min_to_train: 1000
  max_ratio_of_train_steps_to_transitions: 1.0
  max_idle_training_steps: 100
  batch_size: 256
  learning_rate: 1e-3
  train_every: 1
  save_every: 1000
  save_location: checkpoints/${now:%Y-%m-%d_%H-%M-%S}
  target_update_every: 1000
  update_player_every: 100
  max_gradient_norm: 1.0
  gamma: 0.9
logger: 
  writer_prefix: null